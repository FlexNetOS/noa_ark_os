# NOA Auto-Generated Configuration v1.1.5
server:
  host: 127.0.0.1
  port: 8081
  threads: 32
  gpu_layers: 99
  gpu_split: "32000,32000"
  main_gpu: 0
  tensor_split: "1,1"

models:
  - name: default
    path: ./models/
    context_size: 16384
    batch_size: 4235
    n_parallel: 17

inference:
  temperature: 0.7
  top_p: 0.9
  max_tokens: 4096
  flash_attention: true
  low_vram: false
  use_mmap: false
  use_mlock: true

performance:
  timeout: 600
  max_concurrent: 32
  queue_size: 200

logging:
  level: info
  file: ./logs/server-green-v1.1.5.log
